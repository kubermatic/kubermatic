groups:
- name: kubermatic
  rules:
  - alert: KubermaticAPIDown
    expr: absent(up{job="kubermatic-api"} == 1)
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "Kubermatic API is down for more than 5 minutes."
      summary: "Kubermatic API is down"
  - alert: KubermaticControllerManagerDown
    expr: absent(up{job="kubermatic-controller-manager"} == 1)
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "Kubermatic Controller Manager is down for more than 5 minutes."
      summary: "Kubermatic Controller Manager is down"
  - alert: KubermaticUnhandledErrorsTotal
    expr: sum(rate(kubermatic_cluster_controller_unhandled_errors_total[5m])) > 0.01
    for: 10m
    labels:
      severity: warning
    annotations:
      description: "Average increase of unhandled errors in the controller sync loop is greater than 0.25. The metric has been collected over 5min duration."
      summary: "Too many unhandled errors"
  - alert: KubermaticClusterPhase
    expr: kubermatic_cluster_controller_cluster_status_phase{phase="running"} == 0 and
      kubermatic_cluster_controller_cluster_status_phase{phase="deleting"} == 0
    for: 10m
    labels:
      severity: warning
    annotations:
      description: "Cluster {{ $labels.cluster }} is in phase '{{ $labels.phase }}' for more then 10min."
      summary: "Cluster too long in unexpected phase"
