groups:
- name: k8s.rules
  rules:
  - expr: |
      sum(rate(container_cpu_usage_seconds_total{job="cadvisor", image!=""}[5m])) by (namespace)
    record: namespace:container_cpu_usage_seconds_total:sum_rate
  - expr: |
      sum(container_memory_usage_bytes{job="cadvisor", image!=""}) by (namespace)
    record: namespace:container_memory_usage_bytes:sum
  - expr: |
      sum by (namespace, label_name) (
         sum(rate(container_cpu_usage_seconds_total{job="cadvisor", image!=""}[5m])) by (namespace, pod_name)
       * on (namespace, pod_name) group_left(label_name)
         label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:container_cpu_usage_seconds_total:sum_rate
  - expr: |
      sum by (namespace, label_name) (
        sum(container_memory_usage_bytes{job="cadvisor",image!=""}) by (pod_name, namespace)
      * on (namespace, pod_name) group_left(label_name)
        label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:container_memory_usage_bytes:sum
  - expr: |
      sum by (namespace, label_name) (
        sum(kube_pod_container_resource_requests_memory_bytes{job="kube-state-metrics"}) by (namespace, pod)
      * on (namespace, pod) group_left(label_name)
        label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:kube_pod_container_resource_requests_memory_bytes:sum
  - expr: |
      sum by (namespace, label_name) (
        sum(kube_pod_container_resource_requests_cpu_cores{job="kube-state-metrics"} and on(pod) kube_pod_status_scheduled{condition="true"}) by (namespace, pod)
      * on (namespace, pod) group_left(label_name)
        label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
      )
    record: namespace_name:kube_pod_container_resource_requests_cpu_cores:sum
- name: kube-scheduler.rules
  rules:
  - expr: |
      histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.99, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:scheduler_binding_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:scheduler_binding_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:scheduler_binding_latency:histogram_quantile
- name: kube-apiserver.rules
  rules:
  - expr: |
      histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
- name: node.rules
  rules:
  - expr: sum(min(kube_pod_info) by (node))
    record: ':kube_pod_info_node_count:'
  - expr: |
      max(label_replace(kube_pod_info{job="kube-state-metrics"}, "pod", "$1", "pod", "(.*)")) by (node, namespace, pod)
    record: 'node_namespace_pod:kube_pod_info:'
  - expr: |
      count by (node) (sum by (node, cpu) (
        node_cpu{app="node-exporter"}
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      ))
    record: node:node_num_cpu:sum
  - expr: |
      1 - avg(rate(node_cpu{app="node-exporter",mode="idle"}[1m]))
    record: :node_cpu_utilisation:avg1m
  - expr: |
      1 - avg by (node) (
        rate(node_cpu{app="node-exporter",mode="idle"}[1m])
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:)
    record: node:node_cpu_utilisation:avg1m
  - expr: |
      sum(node_load1{app="node-exporter"})
      /
      sum(node:node_num_cpu:sum)
    record: ':node_cpu_saturation_load1:'
  - expr: |
      sum by (node) (
        node_load1{app="node-exporter"}
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
      /
      node:node_num_cpu:sum
    record: 'node:node_cpu_saturation_load1:'
  - expr: |
      1 -
      sum(node_memory_MemFree{app="node-exporter"} + node_memory_Cached{app="node-exporter"} + node_memory_Buffers{app="node-exporter"})
      /
      sum(node_memory_MemTotal{app="node-exporter"})
    record: ':node_memory_utilisation:'
  - expr: |
      sum by (node) (
        (node_memory_MemFree{app="node-exporter"} + node_memory_Cached{app="node-exporter"} + node_memory_Buffers{app="node-exporter"})
        * on (namespace, pod) group_left(node)
          node_namespace_pod:kube_pod_info:
      )
    record: node:node_memory_bytes_available:sum
  - expr: |
      sum by (node) (
        node_memory_MemTotal{app="node-exporter"}
        * on (namespace, pod) group_left(node)
          node_namespace_pod:kube_pod_info:
      )
    record: node:node_memory_bytes_total:sum
  - expr: |
      (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
      /
      scalar(sum(node:node_memory_bytes_total:sum))
    record: node:node_memory_utilisation:ratio
  - expr: |
      1e3 * sum(
        (rate(node_vmstat_pgpgin{app="node-exporter"}[1m])
       + rate(node_vmstat_pgpgout{app="node-exporter"}[1m]))
      )
    record: :node_memory_swap_io_bytes:sum_rate
  - expr: |
      1 -
      sum by (node) (
        (node_memory_MemFree{app="node-exporter"} + node_memory_Cached{app="node-exporter"} + node_memory_Buffers{app="node-exporter"})
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
      /
      sum by (node) (
        node_memory_MemTotal{app="node-exporter"}
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: 'node:node_memory_utilisation:'
  - expr: |
      1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
    record: 'node:node_memory_utilisation_2:'
  - expr: |
      1e3 * sum by (node) (
        (rate(node_vmstat_pgpgin{app="node-exporter"}[1m])
       + rate(node_vmstat_pgpgout{app="node-exporter"}[1m]))
       * on (namespace, pod) group_left(node)
         node_namespace_pod:kube_pod_info:
      )
    record: node:node_memory_swap_io_bytes:sum_rate
  - expr: |
      avg(irate(node_disk_io_time_ms{app="node-exporter",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3)
    record: :node_disk_utilisation:avg_irate
  - expr: |
      avg by (node) (
        irate(node_disk_io_time_ms{app="node-exporter",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_disk_utilisation:avg_irate
  - expr: |
      avg(irate(node_disk_io_time_weighted{app="node-exporter",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3)
    record: :node_disk_saturation:avg_irate
  - expr: |
      avg by (node) (
        irate(node_disk_io_time_weighted{app="node-exporter",device=~"(sd|xvd|nvme).+"}[1m]) / 1e3
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_disk_saturation:avg_irate
  - expr: |
      sum(irate(node_network_receive_bytes{app="node-exporter",device="eth0"}[1m])) +
      sum(irate(node_network_transmit_bytes{app="node-exporter",device="eth0"}[1m]))
    record: :node_net_utilisation:sum_irate
  - expr: |
      sum by (node) (
        (irate(node_network_receive_bytes{app="node-exporter",device="eth0"}[1m]) +
        irate(node_network_transmit_bytes{app="node-exporter",device="eth0"}[1m]))
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_net_utilisation:sum_irate
  - expr: |
      sum(irate(node_network_receive_drop{app="node-exporter",device="eth0"}[1m])) +
      sum(irate(node_network_transmit_drop{app="node-exporter",device="eth0"}[1m]))
    record: :node_net_saturation:sum_irate
  - expr: |
      sum by (node) (
        (irate(node_network_receive_drop{app="node-exporter",device="eth0"}[1m]) +
        irate(node_network_transmit_drop{app="node-exporter",device="eth0"}[1m]))
      * on (namespace, pod) group_left(node)
        node_namespace_pod:kube_pod_info:
      )
    record: node:node_net_saturation:sum_irate
- name: kubermatic
  rules:
  - alert: KubermaticTooManyUnhandledErrors
    annotations:
      message: Kubermatic Controller Manager in {{ $labels.namespace }} has too many
        errors in its loop.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubermatictoomanyunhandlederrors
    expr: |
      sum(rate(kubermatic_cluster_controller_unhandled_errors_total[5m])) > 0.01
    for: 10m
    labels:
      severity: warning
  - alert: KubermaticStuckClusterPhase
    annotations:
      message: Kubermatic cluster {{ $labels.cluster }} is stuck in unexpected phase
        {{ $labels.phase }}.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubermaticstuckclusterphase
    expr: |
      kubermatic_cluster_controller_cluster_status_phase{phase="running"} == 0 and
      kubermatic_cluster_controller_cluster_status_phase{phase="deleting"} == 0
    for: 10m
    labels:
      severity: warning
- name: kubernetes-absent
  rules:
  - alert: CadvisorDown
    annotations:
      message: Cadvisor has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cadvisordown
    expr: |
      absent(up{job="cadvisor"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeAPIDown
    annotations:
      message: KubeAPI has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown
    expr: |
      absent(up{job="apiserver"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeControllerManagerDown
    annotations:
      message: KubeControllerManager has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown
    expr: |
      absent(up{job="kube-controller-manager"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeSchedulerDown
    annotations:
      message: KubeScheduler has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown
    expr: |
      absent(up{job="kube-scheduler"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeStateMetricsDown
    annotations:
      message: KubeStateMetrics has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatemetricsdown
    expr: |
      absent(up{job="kube-state-metrics"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeletDown
    annotations:
      message: Kubelet has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
    expr: |
      absent(up{job="kubelet"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubermaticAPIDown
    annotations:
      message: KubermaticAPI has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubermaticapidown
    expr: |
      absent(up{job="pods",namespace="kubermatic",role="kubermatic-api"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubermaticControllerManagerDown
    annotations:
      message: KubermaticControllerManager has disappeared from Prometheus target
        discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubermaticcontrollermanagerdown
    expr: |
      absent(up{job="pods",namespace="kubermatic",role="controller-manager"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubernetesApiserverDown
    annotations:
      message: KubernetesApiserver has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubernetesapiserverdown
    expr: |
      absent(up{job="apiserver"} == 1)
    for: 15m
    labels:
      severity: critical
- name: kubernetes-apps
  rules:
  - alert: KubePodCrashLooping
    annotations:
      message: '{{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }})
        is restarting {{ printf "%.2f" $value }} / second'
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
    expr: |
      rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[15m]) > 0
    for: 1h
    labels:
      severity: critical
  - alert: KubePodNotReady
    annotations:
      message: '{{ $labels.namespace }}/{{ $labels.pod }} is not ready.'
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
    expr: |
      sum by (namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", phase!~"Running|Succeeded"}) > 0
    for: 1h
    labels:
      severity: critical
  - alert: KubeDeploymentGenerationMismatch
    annotations:
      message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} generation
        mismatch
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
    expr: |
      kube_deployment_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_deployment_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical
  - alert: KubeDeploymentReplicasMismatch
    annotations:
      message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} replica
        mismatch
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch
    expr: |
      kube_deployment_spec_replicas{job="kube-state-metrics"}
        !=
      kube_deployment_status_replicas_available{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical
  - alert: KubeStatefulSetReplicasMismatch
    annotations:
      message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} replica
        mismatch
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch
    expr: |
      kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
        !=
      kube_statefulset_status_replicas{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical
  - alert: KubeStatefulSetGenerationMismatch
    annotations:
      message: StatefulSet {{ $labels.namespace }}/{{ labels.statefulset }} generation
        mismatch
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch
    expr: |
      kube_statefulset_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_statefulset_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical
  - alert: KubeDaemonSetRolloutStuck
    annotations:
      message: Only {{$value}}% of desired pods scheduled and ready for daemon set
        {{$labels.namespace}}/{{$labels.daemonset}}
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
    expr: |
      kube_daemonset_status_number_ready{job="kube-state-metrics"}
        /
      kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} * 100 < 100
    for: 15m
    labels:
      severity: critical
  - alert: KubeDaemonSetNotScheduled
    annotations:
      message: A number of pods of daemonset {{$labels.namespace}}/{{$labels.daemonset}}
        are not scheduled.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
    expr: |
      kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        -
      kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning
  - alert: KubeDaemonSetMisScheduled
    annotations:
      message: A number of pods of daemonset {{$labels.namespace}}/{{$labels.daemonset}}
        are running where they are not supposed to run.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
    expr: |
      kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning
  - alert: KubeCronJobRunning
    annotations:
      message: CronJob {{ $labels.namespaces }}/{{ $labels.cronjob }} is taking more
        than 1h to complete.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecronjobrunning
    expr: |
      time() - kube_cronjob_next_schedule_time{job="kube-state-metrics"} > 3600
    for: 1h
    labels:
      severity: warning
  - alert: KubeJobCompletion
    annotations:
      message: Job {{ $labels.namespaces }}/{{ $labels.job }} is taking more than
        1h to complete.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobcompletion
    expr: |
      kube_job_spec_completions{job="kube-state-metrics"} - kube_job_status_succeeded{job="kube-state-metrics"}  > 0
    for: 1h
    labels:
      severity: warning
  - alert: KubeJobFailed
    annotations:
      message: Job {{ $labels.namespaces }}/{{ $labels.job }} failed to complete.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
    expr: |
      kube_job_status_failed{job="kube-state-metrics"}  > 0
    for: 1h
    labels:
      severity: warning
- name: kubernetes-resources
  rules:
  - alert: KubeCPUOvercommit
    annotations:
      message: Overcommited CPU resource requests on Pods, cannot tolerate node failure.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
    expr: |
      sum(namespace_name:kube_pod_container_resource_requests_cpu_cores:sum)
        /
      sum(node:node_num_cpu:sum)
        >
      (count(node:node_num_cpu:sum)-1) / count(node:node_num_cpu:sum)
    for: 5m
    labels:
      severity: warning
  - alert: KubeMemOvercommit
    annotations:
      message: Overcommited Memory resource requests on Pods, cannot tolerate node
        failure.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit
    expr: |
      sum(namespace_name:kube_pod_container_resource_requests_memory_bytes:sum)
        /
      sum(node_memory_MemTotal)
        >
      (count(node:node_num_cpu:sum)-1)
        /
      count(node:node_num_cpu:sum)
    for: 5m
    labels:
      severity: warning
  - alert: KubeCPUOvercommit
    annotations:
      message: Overcommited CPU resource request quota on Namespaces.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
    expr: |
      sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="requests.cpu"})
        /
      sum(node:node_num_cpu:sum)
        > 1.5
    for: 5m
    labels:
      severity: warning
  - alert: KubeMemOvercommit
    annotations:
      message: Overcommited Memory resource request quota on Namespaces.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit
    expr: |
      sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="requests.memory"})
        /
      sum(node_memory_MemTotal{app="node-exporter"})
        > 1.5
    for: 5m
    labels:
      severity: warning
  - alert: KubeQuotaExceeded
    annotations:
      message: '{{ printf "%0.0f" $value }}% usage of {{ $labels.resource }} in namespace
        {{ $labels.namespace }}.'
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded
    expr: |
      100 * kube_resourcequota{job="kube-state-metrics", type="used"}
        / ignoring(instance, job, type)
      kube_resourcequota{job="kube-state-metrics", type="hard"}
        > 90
    for: 15m
    labels:
      severity: warning
- name: kubernetes-storage
  rules:
  - alert: KubePersistentVolumeUsageCritical
    annotations:
      message: The persistent volume claimed by {{ $labels.persistentvolumeclaim }}
        in namespace {{ $labels.namespace }} has {{ printf "%0.0f" $value }}% free.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeusagecritical
    expr: |
      100 * kubelet_volume_stats_available_bytes{job="kubelet"}
        /
      kubelet_volume_stats_capacity_bytes{job="kubelet"}
        < 3
    for: 1m
    labels:
      severity: critical
  - alert: KubePersistentVolumeFullInFourDays
    annotations:
      message: Based on recent sampling, the persistent volume claimed by {{ $labels.persistentvolumeclaim
        }} in namespace {{ $labels.namespace }} is expected to fill up within four
        days.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefullinfourdays
    expr: |
      predict_linear(kubelet_volume_stats_available_bytes{job="kubelet"}[1h], 4 * 24 * 3600) < 0
    for: 5m
    labels:
      severity: critical
- name: kubernetes-system
  rules:
  - alert: KubeNodeNotReady
    annotations:
      message: '{{ $labels.node }} has been unready for more than an hour'
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
    expr: |
      kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
    for: 1h
    labels:
      severity: warning
  - alert: KubeVersionMismatch
    annotations:
      message: There are {{ $value }} different versions of Kubernetes components
        running.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch
    expr: |
      count(count(kubernetes_build_info{job!="kube-dns"}) by (gitVersion)) > 1
    for: 1h
    labels:
      severity: warning
  - alert: KubeClientErrors
    annotations:
      message: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance
        }}' is experiencing {{ printf "%0.0f" $value }}% errors.'
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
    expr: |
      sum(rate(rest_client_requests_total{code!~"2.."}[5m])) by (instance, job) * 100
        /
      sum(rate(rest_client_requests_total[5m])) by (instance, job)
        > 1
    for: 15m
    labels:
      severity: warning
  - alert: KubeClientErrors
    annotations:
      message: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance
        }}' is experiencing {{ printf "%0.0f" $value }} errors / sec.'
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
    expr: |
      sum(rate(ksm_scrape_error_total{job="kube-state-metrics"}[5m])) by (instance, job) > 0.1
    for: 15m
    labels:
      severity: warning
  - alert: KubeletTooManyPods
    annotations:
      message: Kubelet {{$labels.instance}} is running {{$value}} pods, close to the
        limit of 110.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
    expr: |
      kubelet_running_pod_count{job="kubelet"} > 100
    for: 15m
    labels:
      severity: warning
  - alert: KubeAPILatencyHigh
    annotations:
      message: The API server has a 99th percentile latency of {{ $value }} seconds
        for {{$labels.verb}} {{$labels.resource}}.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh
    expr: |
      cluster_quantile:apiserver_request_latencies:histogram_quantile{job="apiserver",quantile="0.99",subresource!="log",verb!~"^(?:WATCH|WATCHLIST|PROXY|CONNECT)$"} > 1
    for: 10m
    labels:
      severity: warning
  - alert: KubeAPILatencyHigh
    annotations:
      message: The API server has a 99th percentile latency of {{ $value }} seconds
        for {{$labels.verb}} {{$labels.resource}}.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh
    expr: |
      cluster_quantile:apiserver_request_latencies:histogram_quantile{job="apiserver",quantile="0.99",subresource!="log",verb!~"^(?:WATCH|WATCHLIST|PROXY|CONNECT)$"} > 4
    for: 10m
    labels:
      severity: critical
  - alert: KubeAPIErrorsHigh
    annotations:
      message: API server is erroring for {{ $value }}% of requests.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh
    expr: |
      sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m])) without(instance, pod)
        /
      sum(rate(apiserver_request_count{job="apiserver"}[5m])) without(instance, pod) * 100 > 5
    for: 10m
    labels:
      severity: critical
  - alert: KubeAPIErrorsHigh
    annotations:
      message: API server is erroring for {{ $value }}% of requests.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh
    expr: |
      sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m])) without(instance, pod)
        /
      sum(rate(apiserver_request_count{job="apiserver"}[5m])) without(instance, pod) * 100 > 5
    for: 10m
    labels:
      severity: warning
  - alert: KubeClientCertificateExpiration
    annotations:
      message: Kubernetes API certificate is expiring in less than 7 days.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
    expr: |
      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
    labels:
      severity: warning
  - alert: KubeClientCertificateExpiration
    annotations:
      message: Kubernetes API certificate is expiring in less than 1 day.
      runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
    expr: |
      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
    labels:
      severity: critical
- name: etcd
  rules:
  - alert: EtcdInsufficientMembers
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": insufficient members ({{ $value
        }}).'
    expr: |
      count(up{job=~".*etcd.*"} == 0) by (job) > (count(up{job=~".*etcd.*"}) by (job) / 2 - 1)
    for: 3m
    labels:
      severity: critical
  - alert: EtcdNoLeader
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": member {{ $labels.instance }} has
        no leader.'
    expr: |
      etcd_server_has_leader{job=~".*etcd.*"} == 0
    for: 1m
    labels:
      severity: critical
  - alert: EtcdHighNumberOfLeaderChanges
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": instance {{ $labels.instance }}
        has seen {{ $value }} leader changes within the last hour.'
    expr: |
      rate(etcd_server_leader_changes_seen_total{job=~".*etcd.*"}[15m]) > 3
    for: 15m
    labels:
      severity: warning
  - alert: EtcdHighNumberOfFailedGRPCRequests
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{
        $labels.grpc_method }} failed on etcd instance {{ $labels.instance }}.'
    expr: |
      100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*", grpc_code!="OK"}[5m])) BY (job, instance, grpc_service, grpc_method)
        /
      sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m])) BY (job, instance, grpc_service, grpc_method)
        > 1
    for: 10m
    labels:
      severity: warning
  - alert: EtcdHighNumberOfFailedGRPCRequests
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{
        $labels.grpc_method }} failed on etcd instance {{ $labels.instance }}.'
    expr: |
      100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*", grpc_code!="OK"}[5m])) BY (job, instance, grpc_service, grpc_method)
        /
      sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m])) BY (job, instance, grpc_service, grpc_method)
        > 5
    for: 5m
    labels:
      severity: critical
  - alert: EtcdGRPCRequestsSlow
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": gRPC requests to {{ $labels.grpc_method
        }} are taking {{ $value }}s on etcd instance {{ $labels.instance }}.'
    expr: |
      histogram_quantile(0.99, sum(rate(grpc_server_handling_seconds_bucket{job=~".*etcd.*", grpc_type="unary"}[5m])) by (job, instance, grpc_service, grpc_method, le))
      > 0.15
    for: 10m
    labels:
      severity: critical
  - alert: EtcdHighNumberOfFailedHTTPRequests
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": {{ $value }}%% of requests for {{
        $labels.method }} failed on etcd instance {{ $labels.instance }}.'
    expr: |
      100 * sum(rate(etcd_http_failed_total{job=~".*etcd.*"}[5m])) BY (job, instance, method)
        /
      sum(rate(etcd_http_received_total{job=~".*etcd.*"}[5m])) BY (job, instance, method)
        > 1
    for: 10m
    labels:
      severity: warning
  - alert: EtcdHighNumberOfFailedHTTPRequests
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": {{ $value }}%% of requests for {{
        $labels.method }} failed on etcd instance {{ $labels.instance }}.'
    expr: |
      100 * sum(rate(etcd_http_failed_total{job=~".*etcd.*"}[5m])) BY (job, instance, method)
        /
      sum(rate(etcd_http_received_total{job=~".*etcd.*"}[5m])) BY (job, instance, method)
        > 5
    for: 5m
    labels:
      severity: critical
  - alert: EtcdHTTPRequestsSlow
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": HTTP requests to {{ $labels.method
        }} are taking {{ $value }} on etcd instance {{ $labels.instance }}.'
    expr: |
      histogram_quantile(0.99, rate(etcd_http_successful_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.15
    for: 10m
    labels:
      severity: warning
  - alert: EtcdMemberCommunicationSlow
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": member communication with {{ $labels.To
        }} is taking {{ $value }}s on etcd instance {{ $labels.instance }}.'
    expr: |
      histogram_quantile(0.99, rate(etcd_network_peer_round_trip_time_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.15
    for: 10m
    labels:
      severity: warning
  - alert: EtcdHighNumberOfFailedProposals
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": {{ $value }} proposal failures within
        the last hour on etcd instance {{ $labels.instance }}.'
    expr: |
      rate(etcd_server_proposals_failed_total{job=~".*etcd.*"}[15m]) > 5
    for: 15m
    labels:
      severity: warning
  - alert: EtcdHighFsyncDurations
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": 99th percentile fync durations are
        {{ $value }}s on etcd instance {{ $labels.instance }}.'
    expr: |
      histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.5
    for: 10m
    labels:
      severity: warning
  - alert: EtcdHighCommitDurations
    annotations:
      message: 'Etcd cluster "{{ $labels.job }}": 99th percentile commit durations
        {{ $value }}s on etcd instance {{ $labels.instance }}.'
    expr: |
      histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
      > 0.25
    for: 10m
    labels:
      severity: warning
  - expr: process_open_fds / process_max_fds
    record: instance:fd_utilization
  - alert: FdExhaustionClose
    annotations:
      message: '{{ $labels.job }} instance {{ $labels.instance }} will exhaust its
        file descriptors soon'
    expr: |
      predict_linear(instance:fd_utilization{job=~".*etcd.*"}[1h], 3600 * 4) > 1
    for: 10m
    labels:
      severity: warning
  - alert: FdExhaustionClose
    annotations:
      description: '{{ $labels.job }} instance {{ $labels.instance }} will exhaust
        its file descriptors soon'
    expr: |
      predict_linear(instance:fd_utilization{job=~".*etcd.*"}[10m], 3600) > 1
    for: 10m
    labels:
      severity: critical
