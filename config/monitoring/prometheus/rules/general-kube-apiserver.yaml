# This file has been generated, do not edit.
groups:
- name: kube-apiserver
  rules:
  - expr: |
      histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.99"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - expr: |
      histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.9"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - expr: |
      histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
    labels:
      quantile: "0.5"
    record: cluster_quantile:apiserver_request_latencies:histogram_quantile
  - alert: KubernetesApiserverDown
    annotations:
      message: KubernetesApiserver has disappeared from Prometheus target discovery.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubernetesapiserverdown
    expr: absent(up{job="apiserver"} == 1)
    for: 15m
    labels:
      severity: critical
  - alert: KubeAPILatencyHigh
    annotations:
      message: The API server has a 99th percentile latency of {{ $value }} seconds
        for {{ $labels.verb }} {{ $labels.resource }}.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubeapilatencyhigh
    expr: cluster_quantile:apiserver_request_latencies:histogram_quantile{job="apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"}
      > 1
    for: 10m
    labels:
      severity: warning
  - alert: KubeAPILatencyHigh
    annotations:
      message: The API server has a 99th percentile latency of {{ $value }} seconds
        for {{ $labels.verb }} {{ $labels.resource }}.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubeapilatencyhigh
    expr: cluster_quantile:apiserver_request_latencies:histogram_quantile{job="apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"}
      > 4
    for: 10m
    labels:
      severity: critical
  - alert: KubeAPIErrorsHigh
    annotations:
      message: API server is returning errors for {{ $value }}% of requests.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubeapierrorshigh
    expr: |
      sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m])) without(instance, pod)
        /
      sum(rate(apiserver_request_count{job="apiserver"}[5m])) without(instance, pod) * 100 > 10
    for: 10m
    labels:
      severity: critical
  - alert: KubeAPIErrorsHigh
    annotations:
      message: API server is returning errors for {{ $value }}% of requests.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubeapierrorshigh
    expr: |
      sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m])) without(instance, pod)
        /
      sum(rate(apiserver_request_count{job="apiserver"}[5m])) without(instance, pod) * 100 > 5
    for: 10m
    labels:
      severity: warning
  - alert: KubeClientCertificateExpiration
    annotations:
      message: Kubernetes API certificate is expiring in less than 7 days.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubeclientcertificateexpiration
    expr: |
      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
    labels:
      severity: warning
  - alert: KubeClientCertificateExpiration
    annotations:
      message: Kubernetes API certificate is expiring in less than 24 hours.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubeclientcertificateexpiration
    expr: |
      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
    labels:
      severity: critical
