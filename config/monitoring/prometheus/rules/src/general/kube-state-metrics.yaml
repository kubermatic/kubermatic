groups:
- name: kube-state-metrics
  rules:
  - record: ':kube_pod_info_node_count:'
    expr: |
      sum(min(kube_pod_info) by (node))

  - record: 'node_namespace_pod:kube_pod_info:'
    expr: |
      max(kube_pod_info{job="kube-state-metrics"}) by (node, namespace, pod)

  - record: namespace:container_cpu_usage_seconds_total:sum_rate
    expr: |
      sum(rate(container_cpu_usage_seconds_total{job="cadvisor", image!="", container!=""}[5m])) by (namespace)

  - record: namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
    expr: |
      sum by (namespace, pod, container) (
        rate(container_cpu_usage_seconds_total{job="cadvisor", image!="", container!=""}[5m])
      )

  - record: namespace:container_memory_usage_bytes:sum
    expr: |
      sum by (namespace) (
        container_memory_usage_bytes{job="cadvisor", image!="", container!=""}
      )

  - record: namespace_name:container_cpu_usage_seconds_total:sum_rate
    expr: |
      sum by (namespace, label_name) (
          sum(rate(container_cpu_usage_seconds_total{job="cadvisor", image!="", container!=""}[5m])) by (namespace, pod)
        * on (namespace, pod) group_left (label_name)
          kube_pod_labels{job="kube-state-metrics"}
      )

  - record: namespace_name:container_memory_usage_bytes:sum
    expr: |
      sum by (namespace, label_name) (
          sum(container_memory_usage_bytes{job="cadvisor",image!="", container!=""}) by (pod, namespace)
        * on (namespace, pod) group_left (label_name)
          kube_pod_labels{job="kube-state-metrics"}
      )

  - record: namespace_name:kube_pod_container_resource_requests_memory_bytes:sum
    expr: |
      sum by (namespace, label_name) (
          sum(kube_pod_container_resource_requests_memory_bytes{job="kube-state-metrics"}) by (namespace, pod)
        * on (namespace, pod) group_left (label_name)
          kube_pod_labels{job="kube-state-metrics"}
      )

  - record: namespace_name:kube_pod_container_resource_requests_cpu_cores:sum
    expr: |
      sum by (namespace, label_name) (
          sum(kube_pod_container_resource_requests_cpu_cores{job="kube-state-metrics"} and on(pod) kube_pod_status_scheduled{condition="true"}) by (namespace, pod)
        * on (namespace, pod) group_left (label_name)
          kube_pod_labels{job="kube-state-metrics"}
      )

  ############################################################
  # alerts
  ############################################################

  - alert: KubeStateMetricsDown
    annotations:
      message: KubeStateMetrics has disappeared from Prometheus target discovery.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubestatemetricsdown
    expr: absent(up{job="kube-state-metrics"} == 1)
    for: 15m
    labels:
      severity: critical

  - alert: KubePodCrashLooping
    annotations:
      message:
        Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting
        {{ printf "%.2f" $value }} times / 5 minutes.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubepodcrashlooping
    expr: rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[15m]) * 60 * 5 > 0
    for: 1h
    labels:
      severity: critical
    runbook:
      steps:
      - Check the pod's logs.

  - alert: KubePodNotReady
    annotations:
      message: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than an hour.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubepodnotready
    expr: sum by (namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown"}) > 0
    for: 30m
    labels:
      severity: critical
    runbook:
      steps:
      - Check the pod via `kubectl describe pod [POD]` to find out about scheduling issues.

  - alert: KubeDeploymentGenerationMismatch
    annotations:
      message:
        Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match,
        this indicates that the Deployment has failed but has not been rolled back.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubedeploymentgenerationmismatch
    expr: |
      kube_deployment_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_deployment_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical

  - alert: KubeDeploymentReplicasMismatch
    annotations:
      message:
        Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected
        number of replicas for longer than an hour.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubedeploymentreplicasmismatch
    expr: |
      kube_deployment_spec_replicas{job="kube-state-metrics"}
        !=
      kube_deployment_status_replicas_available{job="kube-state-metrics"}
    for: 1h
    labels:
      severity: critical

  - alert: KubeStatefulSetReplicasMismatch
    annotations:
      message:
        StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected
        number of replicas for longer than 15 minutes.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubestatefulsetreplicasmismatch
    expr: |
      kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
        !=
      kube_statefulset_status_replicas{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical

  - alert: KubeStatefulSetGenerationMismatch
    annotations:
      message:
        StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match,
        this indicates that the StatefulSet has failed but has not been rolled back.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubestatefulsetgenerationmismatch
    expr: |
      kube_statefulset_status_observed_generation{job="kube-state-metrics"}
        !=
      kube_statefulset_metadata_generation{job="kube-state-metrics"}
    for: 15m
    labels:
      severity: critical

  - alert: KubeStatefulSetUpdateNotRolledOut
    annotations:
      message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubestatefulsetupdatenotrolledout
    expr: |
      max without (revision) (
        kube_statefulset_status_current_revision{job="kube-state-metrics"}
          unless
        kube_statefulset_status_update_revision{job="kube-state-metrics"}
      )
        *
      (
        kube_statefulset_replicas{job="kube-state-metrics"}
          !=
        kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
      )
    for: 15m
    labels:
      severity: critical

  - alert: KubeDaemonSetRolloutStuck
    annotations:
      message:
        Only {{ $value }}% of the desired Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }}
        are scheduled and ready.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubedaemonsetrolloutstuck
    expr: |
      kube_daemonset_status_number_ready{job="kube-state-metrics"}
        /
      kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} * 100 < 100
    for: 15m
    labels:
      severity: critical

  - alert: KubeDaemonSetNotScheduled
    annotations:
      message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubedaemonsetnotscheduled
    expr: |
      kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
        -
      kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning

  - alert: KubeDaemonSetMisScheduled
    annotations:
      message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.'
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubedaemonsetmisscheduled
    expr: kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
    for: 10m
    labels:
      severity: warning

  - alert: KubeCronJobRunning
    annotations:
      message: CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more than 1h to complete.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubecronjobrunning
    expr: time() - kube_cronjob_next_schedule_time{job="kube-state-metrics"} > 3600
    for: 1h
    labels:
      severity: warning

  - alert: KubeJobCompletion
    annotations:
      message: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than one hour to complete.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubejobcompletion
    expr: kube_job_spec_completions{job="kube-state-metrics"} - kube_job_status_succeeded{job="kube-state-metrics"} > 0
    for: 1h
    labels:
      severity: warning

  - alert: KubeJobFailed
    annotations:
      message: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubejobfailed
    expr: kube_job_status_failed{job="kube-state-metrics"} > 0
    for: 1h
    labels:
      severity: warning

  - alert: KubeCPUOvercommit
    annotations:
      message: Cluster has overcommitted CPU resource requests for namespaces.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubecpuovercommit
    expr: |
      sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="requests.cpu"})
        /
      sum(node:node_num_cpu:sum)
        > 1.5
    for: 5m
    labels:
      severity: warning

  - alert: KubeCPUOvercommit
    annotations:
      message: Cluster has overcommitted CPU resource requests for pods and cannot tolerate node failure.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubecpuovercommit
    expr: |
      sum(namespace_name:kube_pod_container_resource_requests_cpu_cores:sum)
        /
      sum(node:node_num_cpu:sum)
        >
      (count(node:node_num_cpu:sum)-1) / count(node:node_num_cpu:sum)
    for: 5m
    labels:
      severity: warning

  - alert: KubeMemOvercommit
    annotations:
      message: Cluster has overcommitted memory resource requests for namespaces.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubememovercommit
    expr: |
      sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="requests.memory"})
        /
      sum(node_memory_MemTotal_bytes{app="node-exporter"})
        > 1.5
    for: 5m
    labels:
      severity: warning

  - alert: KubeMemOvercommit
    annotations:
      message: Cluster has overcommitted memory resource requests for pods and cannot tolerate node failure.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubememovercommit
    expr: |
      sum(namespace_name:kube_pod_container_resource_requests_memory_bytes:sum)
        /
      sum(node_memory_MemTotal_bytes)
        >
      (count(node:node_num_cpu:sum)-1)
        /
      count(node:node_num_cpu:sum)
    for: 5m
    labels:
      severity: warning

  - alert: KubeQuotaExceeded
    annotations:
      message: Namespace {{ $labels.namespace }} is using {{ printf "%0.0f" $value }}% of its {{ $labels.resource }} quota.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubequotaexceeded
    expr: |
      100 * kube_resourcequota{job="kube-state-metrics", type="used"}
        / ignoring(instance, job, type)
      (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
        > 90
    for: 15m
    labels:
      severity: warning

  - alert: KubePodOOMKilled
    annotations:
      message:
        Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }}
        has been OOMKilled {{ $value }} times in the last 30 minutes.
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubepodoomkilled
    expr: |
      (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 30m >= 2)
      and
      ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[30m]) == 1
    for: 0m
    labels:
      severity: warning

  - alert: KubeNodeNotReady
    annotations:
      message: '{{ $labels.node }} has been unready for more than an hour.'
      runbook_url: https://docs.kubermatic.io/monitoring/runbook/#alert-kubenodenotready
    expr: kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
    for: 1h
    labels:
      severity: warning
