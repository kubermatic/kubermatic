apiVersion: apps/v1
kind: Deployment
metadata:
  name: envoy
spec:
  replicas: {{ .Values.nodePortProxy.replicas  }}
  selector:
    matchLabels:
      app: nodeport-proxy
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: nodeport-proxy
      annotations:
        kubermatic/scrape: "true"
        kubermatic/scrape_port: "8002"
        kubermatic/metric_path: "/stats/prometheus"
    spec:
      initContainers:
      - name: copy-envoy-config
        image: '{{ .Values.nodePortProxy.image.repository }}:{{ .Values.nodePortProxy.image.tag }}'
        command:
        - /bin/cp
        args:
        - /envoy.yaml
        - /etc/envoy/envoy.yaml
        volumeMounts:
        - mountPath: /etc/envoy
          name: envoy-config

      containers:
      - name: envoy-manager
        image: '{{ .Values.nodePortProxy.image.repository }}:{{ .Values.nodePortProxy.image.tag }}'
        command:
        - /envoy-manager
        args:
        - "-listen-address=:8001"
        - "-envoy-node-name=kube"
        - "-envoy-admin-port=9001"
        - "-envoy-stats-port=8002"
        ports:
        - containerPort: 8001
          name: grpc
          protocol: TCP
        resources:
{{ toYaml .Values.nodePortProxy.resources.envoyManager | indent 10 }}
      - name: envoy
        image: '{{ .Values.nodePortProxy.envoy.image.repository }}:{{ .Values.nodePortProxy.envoy.image.tag }}'
        command:
        - /usr/local/bin/envoy
        args:
        - "-c"
        - "/etc/envoy/envoy.yaml"
        - "--service-cluster"
        - "cluster0"
        - "--service-node"
        - "kube"
        lifecycle:
          preStop:
            exec:
              command:
              - wget
              - -qO-
              - http://127.0.0.1:9001/healthcheck/fail
        ports:
        - containerPort: 8002
          name: stats
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 8002
            scheme: HTTP
          periodSeconds: 3
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /etc/envoy
          name: envoy-config
        resources:
{{ toYaml .Values.nodePortProxy.resources.envoy | indent 10 }}
      imagePullSecrets:
      - name: quay
      restartPolicy: Always
      serviceAccountName: nodeport-proxy
      volumes:
      - name: envoy-config
        emptyDir: {}
      nodeSelector:
{{ toYaml .Values.nodePortProxy.nodeSelector | indent 8 }}
      affinity:
{{ toYaml .Values.nodePortProxy.affinity | indent 8 }}
      tolerations:
{{ toYaml .Values.nodePortProxy.tolerations | indent 8 }}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lb-updater
spec:
  selector:
    matchLabels:
      app: lb-updater
  replicas: 1
  template:
    metadata:
      labels:
        app: lb-updater
    spec:
      serviceAccountName: nodeport-proxy
      containers:
      - name: lb-updater
        image: '{{ .Values.nodePortProxy.image.repository }}:{{ .Values.nodePortProxy.image.tag }}'
        command:
        - /lb-updater
        args:
        - "-lb-namespace=$(MY_NAMESPACE)"
        - "-lb-name=nodeport-lb"
        - "-logtostderr"
        env:
        - name: MY_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        resources:
{{ toYaml .Values.nodePortProxy.resources.lbUpdater | indent 10 }}
      imagePullSecrets:
      - name: quay
      nodeSelector:
{{ toYaml .Values.nodePortProxy.lbUpdater.nodeSelector | indent 8 }}
      affinity:
{{ toYaml .Values.nodePortProxy.lbUpdater.affinity | indent 8 }}
      tolerations:
{{ toYaml .Values.nodePortProxy.lbUpdater.tolerations | indent 8 }}
